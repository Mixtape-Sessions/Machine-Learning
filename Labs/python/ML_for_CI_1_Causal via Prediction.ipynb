{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "2Pr-hNx47pl6"
   },
   "outputs": [],
   "source": [
    "# Class practice \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YKjVXkOq5RvM"
   },
   "source": [
    "# Where ML Fits into Causal Inference (review)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8-KSl0ixW31A"
   },
   "source": [
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Mixtape-Sessions/Machine-Learning/blob/main/Labs/python/Causal%20via%20Prediction.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fLMqhUEDwRzf"
   },
   "source": [
    "The traditional go-to tool for causal inference is multiple regression:\n",
    "$$\n",
    "Y_i = \\delta D_i + X_i'\\beta+\\varepsilon_i,\n",
    "$$\n",
    "where $D_i$ is the \"treatment\" or causal variable whose effects we are interested in, and $X_i$ is a vector of controls, conditional on which we are willing to assume $D_i$ is as good as randomly assigned.\n",
    "\n",
    "\n",
    "> *example:* Suppose we are interested in the magnitude of racial discrimination in the labor market. One way to conceptualize this is the difference in earnings between two workers who are identical in productivity, but differ in their race, or, the \"effect\" of race. Then $D_i$ would be an indicator for, say, a Black worker. $Y_i$ would be earnings, and $X_i$ would be characteristics that capture determinants of productivity, including educational attainment, cognitive ability, and other background characteristics.\n",
    "\n",
    "Where does machine learning fit into causal inference? It might be tempting to treat\n",
    "this regression as a prediction exercise where we are predicting $Y_{i}$\n",
    "given $D_{i}$ and $X_{i}$. Don't give in to this temptation. We are not\n",
    "after a prediction for $Y_{i}$, we are after a coefficient on $D_{i}$.\n",
    "Modern machine learning algorithms are finely tuned for producing\n",
    "predictions, but along the way they compromise coefficients. So how can we\n",
    "deploy machine learning in the service of estimating the causal coefficient $\\delta $?\n",
    "\n",
    "To see where ML fits in, first remember that an equivalent way to estimate $%\n",
    "\\delta $ is the following three-step procedure:\n",
    "\n",
    "\n",
    "1.   Regress $Y_{i}$ on $X_{i}$ and compute the residuals, $\\tilde{Y}%\n",
    "_{i}=Y_{i}-\\hat{Y}_{i}^{OLS}$, where $\\hat{Y}_{i}^{OLS}=X_{i}^{\\prime\n",
    "}\\left( X^{\\prime }X\\right) ^{-1}X^{\\prime }Y$\n",
    "2.   Regress $D_{i}$ on $X_{i}$ and compute the residuals, $\\tilde{D}%\n",
    "_{i}=D_{i}-\\hat{D}_{i}^{OLS}$, where $\\hat{D}_{i}^{OLS}=X_{i}^{\\prime\n",
    "}\\left( X^{\\prime }X\\right) ^{-1}X^{\\prime }D$\n",
    "\n",
    "3. Regress $\\tilde{Y}_{i}$ on $\\tilde{D}_{i}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CGpe2nLBpTjr"
   },
   "source": [
    "Steps 1 and 2 are prediction exercises--ML's wheelhouse. When OLS isn't the right tool for the job, we can replace OLS in those steps with machine learning:\n",
    "\n",
    "1.   Predict $Y_{i}$ based on $X_{i}$ using ML and compute the residuals, $\\tilde{Y}%\n",
    "_{i}=Y_{i}-\\hat{Y}_{i}^{ML}$, where $\\hat{Y}_{i}^{ML}$ is the prediction from an ML algorithm\n",
    "2.   Predict $D_{i}$ based on $X_{i}$ using ML and compute the residuals, $\\tilde{D}%\n",
    "_{i}=D_{i}-\\hat{D}_{i}^{ML}$, where $\\hat{D}_{i}^{ML}$ is the prediction from an ML algorithm\n",
    "\n",
    "3. Regress $\\tilde{Y}_{i}$ on $\\tilde{D}_{i}$.\n",
    "\n",
    "This is the basis for the two major methods we'll look at today: The first is \"Post-Double Selection Lasso\" (Belloni, Chernozhukov, Hansen). The second is \"Double-Debiased Machine Learning\" (Chernozhukov, Chetverikov, Demirer, Duflo, Hansen, Newey, Robins)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9YNUJiC_pGHK"
   },
   "source": [
    "# Post Double Selection Lasso (PDS Lasso)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yrGtZGTDbwUN"
   },
   "source": [
    "## Load useful packages: \n",
    "pandas, numpy, linear_model (from sklearn), and KFold (from sklearn.model_selection)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "uK3RIvwKbwUN"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j1aemlN8bwUO"
   },
   "source": [
    "## Read in data and have a look at it\n",
    "We'll use the NLSY data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "7M4VPND9bwUO"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lnw_2016</th>\n",
       "      <th>educ</th>\n",
       "      <th>black</th>\n",
       "      <th>hispanic</th>\n",
       "      <th>other</th>\n",
       "      <th>exp</th>\n",
       "      <th>afqt</th>\n",
       "      <th>mom_educ</th>\n",
       "      <th>dad_educ</th>\n",
       "      <th>yhea_100_1997</th>\n",
       "      <th>...</th>\n",
       "      <th>_XPexp_13</th>\n",
       "      <th>_XPexp_14</th>\n",
       "      <th>_XPexp_16</th>\n",
       "      <th>_XPexp_17</th>\n",
       "      <th>_XPexp_18</th>\n",
       "      <th>_XPexp_19</th>\n",
       "      <th>_XPexp_20</th>\n",
       "      <th>_XPexp_21</th>\n",
       "      <th>_XPexp_22</th>\n",
       "      <th>_XPexp_23</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.076898</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>7.0724</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.294138</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>4.7481</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.830896</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>1.1987</td>\n",
       "      <td>12</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.306459</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>8.9321</td>\n",
       "      <td>16</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.991465</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>2.2618</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1261</th>\n",
       "      <td>1.833475</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>3.8179</td>\n",
       "      <td>15</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1262</th>\n",
       "      <td>3.341985</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>3.3043</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1263</th>\n",
       "      <td>-0.928125</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>1.0319</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1264</th>\n",
       "      <td>3.702931</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>8.5093</td>\n",
       "      <td>16</td>\n",
       "      <td>19</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1265</th>\n",
       "      <td>-1.348073</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0.1059</td>\n",
       "      <td>10</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1266 rows × 994 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      lnw_2016  educ  black  hispanic  other  exp    afqt  mom_educ  dad_educ  \\\n",
       "0     4.076898    16      0         0      0   11  7.0724        12        12   \n",
       "1     3.294138     9      0         0      0   19  4.7481         9        10   \n",
       "2     2.830896     9      0         1      0   22  1.1987        12         9   \n",
       "3     4.306459    16      0         0      0   13  8.9321        16        18   \n",
       "4     5.991465    16      0         1      0   15  2.2618        16        16   \n",
       "...        ...   ...    ...       ...    ...  ...     ...       ...       ...   \n",
       "1261  1.833475    14      1         0      0   17  3.8179        15        12   \n",
       "1262  3.341985     9      0         1      0   20  3.3043        12        11   \n",
       "1263 -0.928125    10      1         0      0   19  1.0319        10        13   \n",
       "1264  3.702931    18      0         0      0   12  8.5093        16        19   \n",
       "1265 -1.348073    11      0         1      0   20  0.1059        10        12   \n",
       "\n",
       "      yhea_100_1997  ...  _XPexp_13  _XPexp_14  _XPexp_16  _XPexp_17  \\\n",
       "0                 3  ...          0          0          0          0   \n",
       "1                 2  ...          0          0          0          0   \n",
       "2                 3  ...          0          0          0          0   \n",
       "3                 2  ...          1          0          0          0   \n",
       "4                 1  ...          0          0          0          0   \n",
       "...             ...  ...        ...        ...        ...        ...   \n",
       "1261              2  ...          0          0          0          1   \n",
       "1262              2  ...          0          0          0          0   \n",
       "1263              2  ...          0          0          0          0   \n",
       "1264              2  ...          0          0          0          0   \n",
       "1265              2  ...          0          0          0          0   \n",
       "\n",
       "      _XPexp_18  _XPexp_19  _XPexp_20  _XPexp_21  _XPexp_22  _XPexp_23  \n",
       "0             0          0          0          0          0          0  \n",
       "1             0          1          0          0          0          0  \n",
       "2             0          0          0          0          1          0  \n",
       "3             0          0          0          0          0          0  \n",
       "4             0          0          0          0          0          0  \n",
       "...         ...        ...        ...        ...        ...        ...  \n",
       "1261          0          0          0          0          0          0  \n",
       "1262          0          0          1          0          0          0  \n",
       "1263          0          1          0          0          0          0  \n",
       "1264          0          0          0          0          0          0  \n",
       "1265          0          0          1          0          0          0  \n",
       "\n",
       "[1266 rows x 994 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlsy=pd.read_csv('https://github.com/Mixtape-Sessions/Machine-Learning/blob/main/Labs/data/nlsy97.csv?raw=true')\n",
    "nlsy\n",
    "# 944 cols , outcome = lnw_2016, treatment= black"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zTkTBC_GbwUO"
   },
   "source": [
    "## Define outcome, regressor of interest\n",
    "y = lnw_2016\n",
    "\n",
    "d = black "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "K9yDNfWbbwUO"
   },
   "outputs": [],
   "source": [
    "y=nlsy['lnw_2016']\n",
    "d=nlsy[['black']] # return as dataframe\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QiITTR5XfOPB"
   },
   "source": [
    "## Simple Regression with no Controls\n",
    "Regress y on d and print out coefficient\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6LOBDO9nulyf"
   },
   "outputs": [],
   "source": [
    "# instantiate and fit a linear regression object\n",
    "\n",
    "# print out regression coefficient\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "lawwWrR0bwUO"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simple regression race gap: -0.382\n"
     ]
    }
   ],
   "source": [
    "lm = linear_model.LinearRegression().fit(d,y)\n",
    "print(\"Simple regression race gap: {:.3f}\".format(lm.coef_[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "10ZQ5f0Q5c-X"
   },
   "source": [
    "### ...\n",
    "Let's try a regression where we control for a few things: education (linearly), experience (linearly), and cognitive ability (afqt, linearly).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "wNHm2Mwg52RK"
   },
   "outputs": [],
   "source": [
    "# define X, matrix of the d and the controls we want\n",
    "\n",
    "# run regression\n",
    "\n",
    "# print out coefficient\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "kLO-WdCR6FtP"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiple regression-adjusted race gap: -0.262\n"
     ]
    }
   ],
   "source": [
    "# define RHS, matrix of the d and the controls we want\n",
    "RHS = nlsy[['black','educ','exp','afqt']]\n",
    "# run regression\n",
    "lm.fit(RHS,y)\n",
    "# print out coefficient\n",
    "print(\"Multiple regression-adjusted race gap: {:.3f}\".format(lm.coef_[0]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XwwdXTfI6sRS"
   },
   "source": [
    "\n",
    "###...\n",
    "How does it compare to the simple regression? \n",
    "\n",
    "But who is to say the controls we included are sufficient? We have a whole host (hundred!) of other potential controls, not to mention that perhaps the controls we did put in enter linearly. This is a job for ML!\n",
    "\n",
    "To prep, let's define a matrix X with all of our potential controls:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "8pcdH08j7M-f"
   },
   "outputs": [],
   "source": [
    "X = nlsy.drop(columns=['lnw_2016','black'])\n",
    "# use all var. except outcome and treatment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FyLr9G2BbwUP"
   },
   "source": [
    "## Post Double Selection Lasso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GV680gb4fH9J"
   },
   "source": [
    "### Step 1: Lasso the outcome on X\n",
    " Don't forget to standard Xs, or choose the normalize=True option"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "utBluzYMbwUP"
   },
   "outputs": [],
   "source": [
    "lassoy = linear_model.LassoCV(max_iter=1000,normalize=True).fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ayb8h1TabwUP"
   },
   "source": [
    "### Step 2: Lasso the treatment on X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "a8TQIG_MbwUP"
   },
   "outputs": [],
   "source": [
    "lassod = linear_model.LassoCV(max_iter=1000,normalize=True).fit(X, d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YRT_TCtZbwUP"
   },
   "source": [
    "### Step 3: Form the union of controls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "Soyb1kuFbwUP"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>educ</th>\n",
       "      <th>hispanic</th>\n",
       "      <th>other</th>\n",
       "      <th>afqt</th>\n",
       "      <th>mom_educ</th>\n",
       "      <th>yhea_2200_1997</th>\n",
       "      <th>youth_bothbio_01_1997</th>\n",
       "      <th>p4_001_1997</th>\n",
       "      <th>p5_102_1997</th>\n",
       "      <th>cv_bio_mom_age_child1_1997</th>\n",
       "      <th>...</th>\n",
       "      <th>_BGhfp_adhr_16</th>\n",
       "      <th>_BGhfp_adpe_2</th>\n",
       "      <th>_BGhfp_adpe_9</th>\n",
       "      <th>_BGhfp_adpe_11</th>\n",
       "      <th>_BGhfp_aden_4</th>\n",
       "      <th>_BGhp5_101__4</th>\n",
       "      <th>_BGhcvc_govo2</th>\n",
       "      <th>_BGhcvc_govp5</th>\n",
       "      <th>_BGhcvc_govp6</th>\n",
       "      <th>_XPexp_17</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.0724</td>\n",
       "      <td>12</td>\n",
       "      <td>98</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>-4</td>\n",
       "      <td>31</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.7481</td>\n",
       "      <td>9</td>\n",
       "      <td>140</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-4</td>\n",
       "      <td>25</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.1987</td>\n",
       "      <td>12</td>\n",
       "      <td>185</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>-4</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.9321</td>\n",
       "      <td>16</td>\n",
       "      <td>140</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>-4</td>\n",
       "      <td>25</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.2618</td>\n",
       "      <td>16</td>\n",
       "      <td>145</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>-4</td>\n",
       "      <td>24</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 140 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   educ  hispanic  other    afqt  mom_educ  yhea_2200_1997  \\\n",
       "0    16         0      0  7.0724        12              98   \n",
       "1     9         0      0  4.7481         9             140   \n",
       "2     9         1      0  1.1987        12             185   \n",
       "3    16         0      0  8.9321        16             140   \n",
       "4    16         1      0  2.2618        16             145   \n",
       "\n",
       "   youth_bothbio_01_1997  p4_001_1997  p5_102_1997  \\\n",
       "0                      1            2           -4   \n",
       "1                      1            1           -4   \n",
       "2                      1            3           -4   \n",
       "3                      1            2           -4   \n",
       "4                      1            2           -4   \n",
       "\n",
       "   cv_bio_mom_age_child1_1997  ...  _BGhfp_adhr_16  _BGhfp_adpe_2  \\\n",
       "0                          31  ...               0              1   \n",
       "1                          25  ...               0              1   \n",
       "2                          30  ...               0              0   \n",
       "3                          25  ...               0              1   \n",
       "4                          24  ...               0              0   \n",
       "\n",
       "   _BGhfp_adpe_9  _BGhfp_adpe_11  _BGhfp_aden_4  _BGhp5_101__4  _BGhcvc_govo2  \\\n",
       "0              0               0              1              0              0   \n",
       "1              0               0              1              0              0   \n",
       "2              0               0              0              0              0   \n",
       "3              0               0              0              0              0   \n",
       "4              0               0              0              0              0   \n",
       "\n",
       "   _BGhcvc_govp5  _BGhcvc_govp6  _XPexp_17  \n",
       "0              0              0          0  \n",
       "1              0              0          0  \n",
       "2              0              0          0  \n",
       "3              0              0          0  \n",
       "4              0              0          0  \n",
       "\n",
       "[5 rows x 140 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xunion=X.iloc[:,(lassod.coef_!=0) + (lassoy.coef_!=0)]\n",
    "Xunion.head()\n",
    "# select input var and only keep the the ones that coeff != 0 ---> only 140 col left "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1Anw8-QibwUP"
   },
   "source": [
    "### Concatenate treatment with union of controls and regress y on that and print out estimate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "gm3RT7ObbwUP"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PDS regression earnings race gap: -0.241\n"
     ]
    }
   ],
   "source": [
    "rhs = pd.concat([d,Xunion],axis=1)\n",
    "fullreg = linear_model.LinearRegression().fit(rhs,y)\n",
    "print(\"PDS regression earnings race gap: {:.3f}\".format(fullreg.coef_[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-ub3mDLFbwUP"
   },
   "source": [
    "## Double-Debiased Machine Learning\n",
    "For simplicity, we will first do it without sample splitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LfsIjhZLjRSc"
   },
   "source": [
    "### Step 1: Ridge outcome on Xs, get residuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "Da9pdvv1leOC"
   },
   "outputs": [],
   "source": [
    "ridgey = linear_model.RidgeCV(normalize=True).fit(X, y)\n",
    "yresid = y-ridgey.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "njrC3DP7l83X"
   },
   "source": [
    "### Step 2: Ridge treatment on Xs, get residuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "Wkcwyi8ImBNa"
   },
   "outputs": [],
   "source": [
    "ridged = linear_model.RidgeCV(normalize=True).fit(X, d)\n",
    "dresid = d-ridged.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "938Uw1dXmKop"
   },
   "source": [
    "### Step 3: Regress y resids on d resids and print out estimate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "cp1OX-LwmPUL"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DML regression earnings race gap: -0.290\n"
     ]
    }
   ],
   "source": [
    "dmlreg = linear_model.LinearRegression().fit(dresid,yresid)\n",
    "print(\"DML regression earnings race gap: {:.3f}\".format(dmlreg.coef_[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ea6hN-cTmY_U"
   },
   "source": [
    "### The real thing: with sample splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "CUaFlxFQmp1d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DML regression earnings race gap: -0.246\n"
     ]
    }
   ],
   "source": [
    "# create our sample splitting \"object\"\n",
    "kf = KFold(n_splits=5,shuffle=True,random_state=42)\n",
    "\n",
    "# apply the splits to our Xs\n",
    "kf.get_n_splits(X)\n",
    "\n",
    "# initialize columns for residuals\n",
    "yresid = y*0\n",
    "dresid = d*0\n",
    "\n",
    "# Now loop through each fold\n",
    "ii=0\n",
    "for train_index, test_index in kf.split(X):\n",
    "  X_train, X_test = X.iloc[train_index,:], X.iloc[test_index,:]\n",
    "  y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "  d_train, d_test = d.iloc[train_index,:], d.iloc[test_index,:]\n",
    "  \n",
    "  # Do DML thing\n",
    "  # Ridge y on training folds:\n",
    "  ridgey.fit(X_train, y_train)\n",
    "\n",
    "  # but get residuals in test set\n",
    "  yresid.iloc[test_index]=y_test-ridgey.predict(X_test)\n",
    "  \n",
    "  #Ridge d on training folds\n",
    "  ridged.fit(X_train, d_train)\n",
    "\n",
    "  #but get residuals in test set\n",
    "  dresid.iloc[test_index,:]=d_test-ridged.predict(X_test)\n",
    "\n",
    " \n",
    "# Regress resids\n",
    "dmlreg = linear_model.LinearRegression().fit(dresid,yresid)\n",
    "\n",
    "print(\"DML regression earnings race gap: {:.3f}\".format(dmlreg.coef_[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "DK0VmmtqBBk7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:               lnw_2016   R-squared:                       0.009\n",
      "Model:                            OLS   Adj. R-squared:                  0.009\n",
      "Method:                 Least Squares   F-statistic:                     10.32\n",
      "Date:                Sun, 20 Aug 2023   Prob (F-statistic):            0.00135\n",
      "Time:                        22:09:52   Log-Likelihood:                -1567.6\n",
      "No. Observations:                1266   AIC:                             3139.\n",
      "Df Residuals:                    1264   BIC:                             3149.\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:                  HC3                                         \n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         -0.0008      0.024     -0.033      0.974      -0.047       0.045\n",
      "black         -0.2462      0.077     -3.213      0.001      -0.396      -0.096\n",
      "==============================================================================\n",
      "Omnibus:                      206.275   Durbin-Watson:                   1.675\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             2239.274\n",
      "Skew:                           0.383   Prob(JB):                         0.00\n",
      "Kurtosis:                       9.470   Cond. No.                         3.05\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors are heteroscedasticity robust (HC3)\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "rhs = sm.add_constant(dresid)\n",
    "model = sm.OLS(yresid, rhs)\n",
    "results = model.fit(cov_type='HC3')\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "izctK-2dxxpv"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "Wg1D6fc7sprb",
    "yPXNaDC5tIqx",
    "GorEJmAdt9y6",
    "-flkjNb1umRv",
    "4Jf3kS226D9G",
    "7XBPxADbvSQx",
    "y74HbxclvaZM",
    "91aP0B-AvqB2",
    "Tm4vZXN-v9Ou",
    "iLEeasnUwft7",
    "P2-anrDxwp9l",
    "aqbex0fqwxIy"
   ],
   "provenance": [
    {
     "file_id": "1AC4pReS_CGnqgSQqM8yHB5iwzJDK48_K",
     "timestamp": 1666389241335
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
